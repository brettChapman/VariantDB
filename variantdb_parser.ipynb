{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4d7498d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; padding:5px; background-color:rgb(252, 253, 255); border: 1px solid lightgrey; padding-left: 1em; padding-right: 1em;\">\n",
    "    <font color='red'>Mini Jupyter tutorial<br><br>To run each cell, click the cell and press <kbd>Run</kbd> from the menu bar. This will run any Python code or display any text within the selected cell before highlighting the next cell down. There are two types of cell: A <i>text cell</i> of type <kbd>Markdown</kbd> or <kbd>Heading</kbd> and a <i>code cell</i> of type <kbd>Code</kbd> identifiable with the <span style=\"font-family: courier; color:black; background-color:white;\">In[ ]:</span> to the left of the cell</i>. The type of cell is also identifiable from the dropdown menu in the above menu bar to the right of <kbd>Run</kbd>. Any visual results produced by the code (text/figures) are displayed directly below that cell. Press <kbd>Run</kbd> again until you reach the end of the notebook or alternatively click <kbd>Kernel</kbd><font color='black'>→</font><kbd>Restart and Run All</kbd>. Should the Jupyter notebook crash for any reason, restart the Jupyter Kernel by clicking <kbd>Kernel</kbd><font color='black'>→</font><kbd>Restart</kbd>, and start again from the top.\n",
    "        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7d90df",
   "metadata": {},
   "source": [
    "# VariantDB parser\n",
    "\n",
    "<p style=\\\"text-align: justify\\\">\n",
    "<br>\n",
    "    This workflow parses and annotates input variant CSV files\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d855fa4-2ddd-4c22-a987-697d7cdcf09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gnomad_db.database import gnomAD_DB\n",
    "from natsort import index_natsorted\n",
    "from number_parser import parse_ordinal\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631033b5",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:5px;  border: 1px solid lightgrey; padding-left: 1em; padding-right: 1em;\">\n",
    "\n",
    "<h3 style=\"text-align: justify\">Process all CSV files in the <kbd>input_csv</kbd> folder and annotate them, outputting to the <kbd>output_annotated_csv</kbd> folder</h3>\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b64f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnomad_dir='/Users/brettchapman/gnomeAD_DB' # Specify where the SQLite genomad directory is located\n",
    "internal_db_file='internaldb/internal_database.csv' # Specify the internal database CSV file\n",
    "goi_file='genes_of_interest/genes.csv' # Specify the genes of interest with 'HGNC Approved Gene Symbol' and 'Ion Reporter Gene Symbol' headers\n",
    "\n",
    "#Load in the genes of interest\n",
    "goi = pd.read_csv(goi_file)\n",
    "    \n",
    "goi = goi.rename(columns={'HGNC Approved Gene Symbol': 'GeneSymbol'\n",
    "                              , 'Ion Reporter Gene Symbol': 'Gene'}).reset_index(drop=True)\n",
    "hgnc_goi_list = list(goi['GeneSymbol'])\n",
    "internal_goi_list = list(goi['Gene'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78f747b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in clinvar database (make sure it has been downloaded with download_clinvar.ipynb)\n",
    "clinvar_db = pd.read_csv('variant_summary.txt.gz', compression='gzip', sep='\\t', low_memory=False)\n",
    "\n",
    "#Filter Clinvar database for only variants in GRCh38\n",
    "clinvar_db = clinvar_db[clinvar_db.Assembly == 'GRCh38'].reset_index(drop=True)\n",
    "\n",
    "# Add in Ref and Alt for merging with input CSV\n",
    "clinvar_db['Ref'] = clinvar_db['ReferenceAlleleVCF']\n",
    "clinvar_db['Alt'] = clinvar_db['AlternateAlleleVCF']\n",
    "\n",
    "#Filter Clinvar database for only genes of interest\n",
    "clinvar_db = clinvar_db[clinvar_db.GeneSymbol.isin(hgnc_goi_list)]\n",
    "\n",
    "# Retain only clinvar entries of interest\n",
    "clinvar_db = clinvar_db[['GeneSymbol', 'Chromosome', 'Start', 'Stop', 'Ref', 'Alt', 'ClinicalSignificance', 'ReviewStatus', 'NumberSubmitters', 'VariationID']]\n",
    "\n",
    "# Load in internal database\n",
    "internal_db = pd.read_csv(internal_db_file)\n",
    "internal_db.dropna(how='all', axis=1, inplace=True)\n",
    "\n",
    "#dropping check of genome coordinates start and end with internal db\n",
    "internal_db['Chromosome'] = internal_db['Genomic Coordinates'].apply(lambda x: str(x).split(\":\")[0])\n",
    "internal_db = internal_db.drop(columns=['Genomic Coordinates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44918c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewStatus_panel = ['Practice guideline'\n",
    "                     , 'reviewed by expert panel'\n",
    "                     , 'criteria provided, multiple submitters, no conflicts']\n",
    "\n",
    "clinical_pathogenic_panel = ['Pathogenic'\n",
    "                             , 'Pathogenic, low penetrance'\n",
    "                             , 'Pathogenic/Likely pathogenic'\n",
    "                             , 'Likely pathogenic'\n",
    "                             , 'Likely pathogenic, low penetrance'\n",
    "                             , 'Established risk allele'\n",
    "                             , 'Likely risk allele']\n",
    "\n",
    "clinical_benign_panel = ['Benign'\n",
    "                         , 'Likely benign'\n",
    "                         , 'Benign/Likely benign'\n",
    "                         , 'Uncertain significance'\n",
    "                         , 'Uncertain risk allele']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67cf60e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "csv_files = glob.glob(os.path.join(path, \"input_csv/*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7823cdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_sort(col: pd.Series) -> pd.Series:\n",
    "    if col.name == \"Chromosome\":\n",
    "        return col.apply(parse_ordinal)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2df4e353",
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv_file in csv_files:\n",
    "    # read in the input CSV file\n",
    "    input_csv = pd.read_csv(csv_file, skiprows=[0,1])\n",
    "    \n",
    "    output_csv = csv_file.split('/')[-1].split('.csv')[0] + '_annotated.csv'\n",
    "    \n",
    "    #Split the Genomic coodinates into Chromosome, start, stop, and assembly columns\n",
    "    input_csv['Chromosome'] = input_csv['Genomic Coordinates'].apply(lambda x: str(x).split(\":\")[0])\n",
    "    input_csv['Start'] = input_csv['Genomic Coordinates'].apply(lambda x: str(x).split(\":\")[1].split(\"-\")[0])\n",
    "    input_csv['Stop'] = input_csv['Genomic Coordinates'].apply(lambda x: str(x).split(\":\")[1].split(\"-\")[1].split(' ')[0])\n",
    "    input_csv['Start'] = input_csv['Start'].astype(np.int64)\n",
    "    input_csv['Stop'] = input_csv['Stop'].astype(np.int64)\n",
    "    input_csv['Assembly'] = input_csv['Genomic Coordinates'].apply(lambda x: str(x).split(\":\")[1].split(\"-\")[1].split(' ')[1])\n",
    "    \n",
    "    # Ensure variants from input CSV only in GRCH38 for cross comparison with clinvar, gnomeAD and internal database\n",
    "    input_csv = input_csv[input_csv.Assembly == \"(GRCH38)\"].reset_index(drop=True)\n",
    "    \n",
    "    #Filter input CSV for only genes of interest\n",
    "    input_csv = input_csv[input_csv.Gene.isin(internal_goi_list)]\n",
    "    \n",
    "    # Add in the HGNC gene symbol to the input CSV\n",
    "    input_csv = input_csv.merge(goi, left_on='Gene', right_on='Gene').reset_index(drop=True)\n",
    "    \n",
    "    #Merge the input CSV with Clinvar with keys: GeneSymbol, Chromosome, Start, Stop, Ref and Alt\n",
    "    clinvar_match = input_csv.merge(clinvar_db, left_on=['GeneSymbol', 'Chromosome', 'Start', 'Stop', 'Ref', 'Alt']\n",
    "                                    , right_on=['GeneSymbol', 'Chromosome', 'Start', 'Stop', 'Ref', 'Alt']).reset_index(drop=True)\n",
    "    \n",
    "    # Parse the gnomad SQLite database\n",
    "    db = gnomAD_DB(gnomad_dir, genome=\"Grch38\")\n",
    "    \n",
    "    #Remove some ipykernel Future warnings about concatenating empty dataframes.\n",
    "    import warnings\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    \n",
    "    chromosome_intervals = input_csv[['Chromosome', 'Start', 'Stop']]\n",
    "    \n",
    "    df_gnomad = pd.DataFrame()\n",
    "\n",
    "    for index, row in chromosome_intervals.iterrows():\n",
    "        chromosome = row['Chromosome']\n",
    "        start = row['Start']\n",
    "        stop = row['Stop']\n",
    " \n",
    "        if df_gnomad.empty:\n",
    "            df_gnomad = db.get_info_for_interval(chrom=chromosome, interval_start=start, interval_end=stop, query=\"*\")\n",
    "            df_gnomad = df_gnomad[['chrom', 'pos', 'ref', 'alt', 'AF', 'AF_popmax']].reset_index(drop=True)\n",
    "        else:\n",
    "            tmp = db.get_info_for_interval(chrom=chromosome, interval_start=start, interval_end=stop, query=\"*\")\n",
    "            tmp = tmp[['chrom', 'pos', 'ref', 'alt', 'AF', 'AF_popmax']].reset_index(drop=True)        \n",
    "            if df_gnomad.empty:\n",
    "                df_gnomad = db.get_info_for_interval(chrom=chromosome, interval_start=start, interval_end=stop, query=\"*\")\n",
    "                df_gnomad = df_gnomad[['chrom', 'pos', 'ref', 'alt', 'AF', 'AF_popmax']].reset_index(drop=True)            \n",
    "            else:\n",
    "                tmp = db.get_info_for_interval(chrom=chromosome, interval_start=start, interval_end=stop, query=\"*\")\n",
    "                tmp = tmp[['chrom', 'pos', 'ref', 'alt', 'AF', 'AF_popmax']].reset_index(drop=True)\n",
    "                if not tmp.empty:\n",
    "                    df_gnomad = pd.concat([df_gnomad, tmp], axis=0).reset_index(drop=True)\n",
    "  \n",
    "    df_gnomad = df_gnomad.rename(columns={'chrom': 'Chromosome', 'pos': 'Start', 'ref': 'Ref', 'alt': 'Alt'}).reset_index(drop=True)\n",
    "\n",
    "    # Merge the parsed gnomad database with the input CSV\n",
    "    gnomad_match = input_csv.merge(df_gnomad, left_on=['Chromosome', 'Start', 'Ref', 'Alt']\n",
    "                                   , right_on=['Chromosome', 'Start', 'Ref', 'Alt']).reset_index(drop=True)\n",
    "    \n",
    "    # Merge the parsed internal database with the input CSV\n",
    "    #internal_match = input_csv.merge(internal_db, left_on=['Chromosome', 'Gene', 'Start', 'Variant', 'Transcript']\n",
    "    #                                 , right_on=['Chromosome', 'Gene', 'Start', 'Variant', 'Transcript']).reset_index(drop=True)\n",
    "    internal_match = input_csv.merge(internal_db, left_on=['Chromosome', 'Gene', 'Variant', 'Transcript']\n",
    "                                     , right_on=['Chromosome', 'Gene', 'Variant', 'Transcript']).reset_index(drop=True)\n",
    "    \n",
    "    # Merge matches from clinvar, gnomad and internal database, in that order with outer join\n",
    "    clinvar_gnomad_match = pd.merge(clinvar_match, gnomad_match, how='outer').drop_duplicates()\n",
    "    internal_clinvar_gnomad_match = pd.merge(clinvar_gnomad_match, internal_match, how='outer').drop_duplicates()\n",
    "    \n",
    "    # Merge the annotated entries back into the input CSV add in non matches, with outer join, and then sort\n",
    "    annotated_csv = pd.merge(internal_clinvar_gnomad_match, input_csv, how='outer').drop_duplicates()\n",
    "    annotated_csv = annotated_csv.sort_values(by=['Chromosome', 'Gene', 'Start'], key=custom_sort)\n",
    "    \n",
    "    # Populate custom classification columns and reason column\n",
    "    clinvar_conditions = [((annotated_csv.NumberSubmitters >= 3)\n",
    "                    & (annotated_csv.ReviewStatus.isin(reviewStatus_panel))\n",
    "                    & (annotated_csv.ClinicalSignificance.isin(clinical_pathogenic_panel))),\n",
    "                    ((annotated_csv.NumberSubmitters >= 3) \n",
    "                    & (annotated_csv.ReviewStatus.isin(reviewStatus_panel))\n",
    "                    & (annotated_csv.ClinicalSignificance.isin(clinical_benign_panel)))]\n",
    "\n",
    "    annotated_csv['InternalClassification'] = annotated_csv['InternalClassification'].fillna('0')\n",
    "    \n",
    "    clinvar_choices = ['Suspected pathogenic', 'Suspected VUS/benign']\n",
    "    \n",
    "    annotated_csv['ClinVarCustomClassification'] = np.select(clinvar_conditions, clinvar_choices)\n",
    "    \n",
    "    gnomad_conditions = [(annotated_csv.AF >= 0.01) | (annotated_csv.AF_popmax >= 0.01)]\n",
    "    \n",
    "    gnomad_choices = ['Suspected VUS/benign']\n",
    "    \n",
    "    annotated_csv['gnomADCustomClassification'] = np.select(gnomad_conditions, gnomad_choices)\n",
    "\n",
    "    variant_conditions = [(annotated_csv.Variant.astype(str).str.contains(r'\\+1{1}[a-zA-Z]|\\+2{1}[a-zA-Z]|\\-1{1}[a-zA-Z]|\\-2{1}[a-zA-Z]'))\n",
    "                     | (annotated_csv['Protein Change'].astype(str).str.contains(r'Ter|fs'))\n",
    "                     | (~annotated_csv['Copy Number'].isnull()),\n",
    "                     (annotated_csv['Prediction Evidence(PVS1)'].astype(str).str.contains(r'intron|UTR'))\n",
    "                     | (annotated_csv['Protein Change'].str.contains('='))]\n",
    "\n",
    "    variant_choices = ['Suspected pathogenic', 'Suspected VUS/benign']\n",
    "\n",
    "    annotated_csv['VariantEffect'] = np.select(variant_conditions, variant_choices)\n",
    "    \n",
    "    overall_classify_conditions = [(annotated_csv['InternalClassification'] != '0'),\n",
    "                               (annotated_csv['InternalClassification'] == '0')\n",
    "                               & (annotated_csv['ClinVarCustomClassification'] != '0'),\n",
    "                               (annotated_csv['InternalClassification'] == '0')\n",
    "                               & (annotated_csv['ClinVarCustomClassification'] == '0')\n",
    "                               & (annotated_csv['gnomADCustomClassification'] != '0'),\n",
    "                               (annotated_csv['InternalClassification'] == '0')\n",
    "                               & (annotated_csv['ClinVarCustomClassification'] == '0')\n",
    "                               & (annotated_csv['gnomADCustomClassification'] == '0')\n",
    "                               & (annotated_csv['VariantEffect'] != '0'),\n",
    "                               (annotated_csv['InternalClassification'] == '0')\n",
    "                               & (annotated_csv['ClinVarCustomClassification'] == '0')\n",
    "                               & (annotated_csv['gnomADCustomClassification'] == '0')\n",
    "                               & (annotated_csv['VariantEffect'] == '0')]\n",
    "\n",
    "    overall_classify_choices = [\n",
    "                        list(annotated_csv.InternalClassification),\n",
    "                        list(annotated_csv.ClinVarCustomClassification),\n",
    "                        list(annotated_csv.gnomADCustomClassification),\n",
    "                        list(annotated_csv.VariantEffect),\n",
    "                        'Assess further']\n",
    "    \n",
    "    annotated_csv['ClassificationOverall'] = np.select(overall_classify_conditions, overall_classify_choices)\n",
    "    \n",
    "    reason_conditions = overall_classify_conditions[:4]\n",
    "    \n",
    "    reason_choices = ['Internal Database', 'ClinVar', 'gnomAD', 'VariantEffect']\n",
    "    \n",
    "    annotated_csv['Reason'] = np.select(reason_conditions, reason_choices)\n",
    "    \n",
    "    annotated_csv['InternalClassification'].replace(['0', np.nan], '', inplace=True)\n",
    "    annotated_csv['ClinVarCustomClassification'].replace(['0', np.nan], '', inplace=True)\n",
    "    annotated_csv['gnomADCustomClassification'].replace(['0', np.nan], '', inplace=True)\n",
    "    annotated_csv['VariantEffect'].replace(['0', np.nan], '', inplace=True)\n",
    "    annotated_csv['ClassificationOverall'].replace(['0', np.nan], '', inplace=True)\n",
    "    annotated_csv['Reason'].replace(['0', np.nan], '', inplace=True)\n",
    "    \n",
    "    # Write out the annotated CSV file\n",
    "    annotated_csv.to_csv('output_annotated_csv/'+ output_csv, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
